# ä¸Šè¡£åˆ†å‰²æ‰¹é‡å¤„ç†å·¥å…·
# åŠŸèƒ½ï¼šè‡ªåŠ¨æ£€æµ‹æ¨¡ç‰¹ä¸Šè¡£åŒºåŸŸï¼Œç”Ÿæˆé€æ˜èƒŒæ™¯å›¾ç‰‡å’Œæ©ç 
# æ”¯æŒæ ¼å¼ï¼šjpg, jpeg, png

import os
import cv2
import numpy as np
import warnings
from tqdm import tqdm
from PIL import Image
import paddlehub as hub
import time
import sys  # æ–°å¢ç³»ç»Ÿæ¨¡å—

# è®¾ç½®ç³»ç»Ÿç¼–ç ä¸ºUTF-8ï¼ˆè§£å†³ä¸­æ–‡è·¯å¾„é—®é¢˜ï¼‰
sys.stdout.reconfigure(encoding='utf-8') if hasattr(sys.stdout, 'reconfigure') else None
sys.stderr.reconfigure(encoding='utf-8') if hasattr(sys.stderr, 'reconfigure') else None


def top(input_images,output_results):
    warnings.filterwarnings("ignore", category=UserWarning)

    # é…ç½®å‚æ•°
    INPUT_DIR = input_images  # è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆå­˜æ”¾æ¨¡ç‰¹ç…§ç‰‡ï¼‰
    OUTPUT_DIR = output_results  # è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„
    SUPPORTED_EXTS = (".jpg", ".jpeg", ".png")  # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
    MODEL_NAME = "ace2p"  # äººä½“è§£ææ¨¡å‹åç§°
    MAX_SIZE = 1024  # æœ€å¤§å›¾åƒå°ºå¯¸ï¼ˆé•¿è¾¹ï¼‰
    UPPER_CLOTHES_ID = 5  # ä¸Šè¡£ç±»åˆ«ID
    LOWWER_CLOTHES_ID = 9 # ä¸‹è¡£ç±»åˆ«ID
    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    os.makedirs(os.path.join(OUTPUT_DIR, "masks"), exist_ok=True)

    # åŠ è½½äººä½“è§£ææ¨¡å‹
    print(f"â³ æ­£åœ¨åŠ è½½äººä½“è§£ææ¨¡å‹ '{MODEL_NAME}'...")
    try:
        start_time = time.time()
        model = hub.Module(name=MODEL_NAME)
        load_time = time.time() - start_time
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ ({load_time:.2f}ç§’)")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("å°è¯•ä½¿ç”¨å¤‡ç”¨æ¨¡å‹ 'humanseg'...")
        try:
            model = hub.Module(name="humanseg")
            print("âœ… å¤‡ç”¨æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e2:
            print(f"âŒ åŠ è½½å¤‡ç”¨æ¨¡å‹å¤±è´¥: {e2}")
            print("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–å°è¯•é‡æ–°å®‰è£…: pip install --upgrade paddlepaddle paddlehub")
            exit(1)

    # è·å–è¾“å…¥æ–‡ä»¶åˆ—è¡¨
    input_files = []
    for file in os.listdir(INPUT_DIR):
        if file.lower().endswith(SUPPORTED_EXTS):
            input_files.append(file)

    if not input_files:
        print(f"âŒ åœ¨ '{INPUT_DIR}' ä¸­æœªæ‰¾åˆ°æ”¯æŒçš„å›¾ç‰‡æ–‡ä»¶")
        print(f"æ”¯æŒçš„æ ¼å¼: {', '.join(SUPPORTED_EXTS)}")
        exit(1)

    print(f"ğŸ” æ‰¾åˆ° {len(input_files)} ä¸ªå¾…å¤„ç†å›¾ç‰‡")
    # å¤„ç†æ‰€æœ‰å›¾ç‰‡
    success_count = 0
    failure_count = 0
    failure_messages = []

    print("ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†å›¾ç‰‡...")
    start_time = time.time()

    # ä½¿ç”¨tqdmåˆ›å»ºè¿›åº¦æ¡
    for file in tqdm(input_files, desc="å¤„ç†è¿›åº¦", unit="å›¾ç‰‡"):
        input_path = os.path.join(INPUT_DIR, file)
        # ä½¿ç”¨å®‰å…¨æ–‡ä»¶åå¤„ç†ï¼ˆè§£å†³ä¸­æ–‡ä¹±ç ï¼‰
        safe_prefix = file.split('.')[0]  # ç›´æ¥ä½¿ç”¨åŸæ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰

        success, message = process_image(
            input_path,
            safe_prefix,  # ä½¿ç”¨ä¿®æ”¹åçš„å‚æ•°
            MAX_SIZE,
            UPPER_CLOTHES_ID,
            model,
            OUTPUT_DIR
        )

        if success:
            success_count += 1
        else:
            failure_count += 1
            failure_messages.append(message)

    # è®¡ç®—å¤„ç†æ—¶é—´
    total_time = time.time() - start_time

    # æ‰“å°æ‘˜è¦æŠ¥å‘Š
    print("\n" + "=" * 50)
    print(f"ğŸ“Š å¤„ç†æ‘˜è¦")
    print("=" * 50)
    print(f"âœ… æˆåŠŸå¤„ç†: {success_count} å¼ å›¾ç‰‡")
    print(f"âŒ å¤„ç†å¤±è´¥: {failure_count} å¼ å›¾ç‰‡")
    print(f"â±ï¸ æ€»è€—æ—¶: {total_time:.2f}ç§’")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {os.path.abspath(OUTPUT_DIR)}")

    if failure_count > 0:
        print("\nâŒ å¤±è´¥è¯¦æƒ…:")
        for msg in failure_messages:
            print(f"  - {msg}")

    # æ˜¾ç¤ºæ–‡ä»¶å¤¹ç»“æ„
    print("\nğŸ“ è¾“å‡ºæ–‡ä»¶å¤¹ç»“æ„:")
    print(f"  {OUTPUT_DIR}/")
    print(f"  â”œâ”€â”€ masks/         # ä¸Šè¡£æ©ç ï¼ˆäºŒå€¼PNGï¼‰")

    print("\nâœ¨ å¤„ç†å®Œæˆï¼")

# å¤„ç†å‡½æ•°
def process_image(image_path, output_prefix, MAX_SIZE, UPPER_CLOTHES_ID, model, OUTPUT_DIR):
    try:
        # 1. åŠ è½½å›¾åƒ
        pil_img = Image.open(image_path)
        orig_width, orig_height = pil_img.size

        # 2. è°ƒæ•´å¤§å°ï¼ˆä¿æŒæ¯”ä¾‹ï¼‰
        scale_factor = 1.0
        if max(orig_width, orig_height) > MAX_SIZE:
            scale_factor = MAX_SIZE / max(orig_width, orig_height)
            new_width = int(orig_width * scale_factor)
            new_height = int(orig_height * scale_factor)
            pil_img = pil_img.resize((new_width, new_height), Image.LANCZOS)

        # 3. è½¬æ¢ä¸ºOpenCVæ ¼å¼
        img = np.array(pil_img)
        if len(img.shape) == 2:  # ç°åº¦å›¾
            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
        elif img.shape[2] == 4:  # RGBA
            img = cv2.cvtColor(img, cv2.COLOR_RGBA2BGR)
        else:  # RGB
            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)

        # 4. äººä½“è§£æ
        result = model.segmentation(images=[img])
        parsing = result[0]['data']

        # 5. åˆ›å»ºä¸Šè¡£æ©ç 
        upper_mask = (parsing == UPPER_CLOTHES_ID).astype(np.uint8) * 255

        # 6. æå–é€æ˜èƒŒæ™¯çš„ä¸Šè¡£
        bgra = cv2.cvtColor(img, cv2.COLOR_BGR2BGRA)
        bgra[:, :, 3] = np.where(parsing == UPPER_CLOTHES_ID, 255, 0).astype(np.uint8)

        # 7. åˆ›å»ºé¢„è§ˆå›¾åƒ
        preview_img = img.copy()
        preview_img[upper_mask == 255] = (0, 255, 0)  # ç”¨ç»¿è‰²æ ‡è®°ä¸Šè¡£åŒºåŸŸ

        # 8. ä¿å­˜ç»“æœï¼ˆä½¿ç”¨PILä»£æ›¿OpenCVè§£å†³æ–‡ä»¶åç¼–ç é—®é¢˜ï¼‰
        mask_path = os.path.join(OUTPUT_DIR, "masks", f"{output_prefix}_mask.png")

        # ä½¿ç”¨PILä¿å­˜æ©ç ï¼ˆè§£å†³ä¸­æ–‡ä¹±ç ï¼‰
        mask_img = Image.fromarray(upper_mask)
        mask_img.save(mask_path)

        return True, f"å¤„ç†æˆåŠŸ: {os.path.basename(image_path)}"

    except Exception as e:
        return False, f"å¤„ç†å¤±è´¥: {os.path.basename(image_path)} - {str(e)}"

input_images=r"C:\Users\ASUS\Desktop\PRDataSet\model"
output_images=r"C:\Users\ASUS\Desktop\PRDataSet\result"
top(input_images,output_images)